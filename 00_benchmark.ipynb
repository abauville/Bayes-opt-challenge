{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138e3a81-ac90-4dc7-9078-ad6402acf3d8",
   "metadata": {
    "id": "138e3a81-ac90-4dc7-9078-ad6402acf3d8"
   },
   "source": [
    "# Benchmark for bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed945dbd-18cd-414f-ac8a-95683ad432b1",
   "metadata": {
    "id": "ed945dbd-18cd-414f-ac8a-95683ad432b1"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1fff1d5-47e8-4b63-9fd2-e1e30168a7a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17493,
     "status": "ok",
     "timestamp": 1650982583865,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "f1fff1d5-47e8-4b63-9fd2-e1e30168a7a8",
    "outputId": "31b7718d-c505-412d-a00d-cee059d2be43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gpytorch\n",
      "  Downloading gpytorch-1.6.0.tar.gz (310 kB)\n",
      "\u001b[K     |████████████████████████████████| 310 kB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gpytorch\n",
      "  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpytorch: filename=gpytorch-1.6.0-py2.py3-none-any.whl size=509889 sha256=6bd892490c4508ce3c9801a129f2fd6cf7c82f1abf70aeb46120ba6ce0bc0002\n",
      "  Stored in directory: /root/.cache/pip/wheels/66/b5/89/34c06ad393a6feb72b4cdde46d0f1c667f3e2632960f9df109\n",
      "Successfully built gpytorch\n",
      "Installing collected packages: gpytorch\n",
      "Successfully installed gpytorch-1.6.0\n",
      "Collecting botorch\n",
      "  Downloading botorch-0.6.4-py3-none-any.whl (363 kB)\n",
      "\u001b[K     |████████████████████████████████| 363 kB 8.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.7/dist-packages (from botorch) (1.11.0+cu113)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from botorch) (1.4.1)\n",
      "Requirement already satisfied: gpytorch>=1.6 in /usr/local/lib/python3.7/dist-packages (from botorch) (1.6.0)\n",
      "Collecting multipledispatch\n",
      "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
      "Collecting pyro-ppl==1.8.0\n",
      "  Downloading pyro_ppl-1.8.0-py3-none-any.whl (713 kB)\n",
      "\u001b[K     |████████████████████████████████| 713 kB 53.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.8.0->botorch) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.8.0->botorch) (1.21.6)\n",
      "Collecting pyro-api>=0.1.1\n",
      "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.8.0->botorch) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.9->botorch) (4.2.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from multipledispatch->botorch) (1.15.0)\n",
      "Installing collected packages: pyro-api, pyro-ppl, multipledispatch, botorch\n",
      "Successfully installed botorch-0.6.4 multipledispatch-0.6.0 pyro-api-0.1.2 pyro-ppl-1.8.0\n",
      "Cloning into 'Bayes-opt-challenge'...\n",
      "remote: Enumerating objects: 29, done.\u001b[K\n",
      "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
      "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
      "remote: Total 29 (delta 0), reused 29 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (29/29), done.\n"
     ]
    }
   ],
   "source": [
    "running_on_colab = False\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    running_on_colab = True\n",
    "    !pip install gpytorch\n",
    "    !pip install botorch\n",
    "    !git clone https://github.com/abauville/Bayes-opt-challenge.git\n",
    "    !cp /content/Bayes-opt-challenge/bayes_lib.py .\n",
    "\n",
    "from datetime import datetime\n",
    "from bayes_lib import run_experiment\n",
    "from botorch.test_functions.synthetic import Hartmann\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9569d7b-225b-4a96-ba84-eb4dd428639b",
   "metadata": {
    "executionInfo": {
     "elapsed": 11917,
     "status": "ok",
     "timestamp": 1650862791141,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "b9569d7b-225b-4a96-ba84-eb4dd428639b"
   },
   "source": [
    "## Define the ground truth, baseline and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d954da6-44cf-4255-9b5f-e78e17429a0a",
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1650982589193,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "9d954da6-44cf-4255-9b5f-e78e17429a0a"
   },
   "outputs": [],
   "source": [
    "def gt_func(x):\n",
    "    \"\"\"Ground truth function: negative hartmann 6\n",
    "    The Bayes opt library we use aims to maximize functions by default.\n",
    "    We use the negated function to effectively minimize it, i.e. argmin(f(x)) = argmax(-f(x))\n",
    "    \"\"\"\n",
    "    hart = Hartmann()\n",
    "    return - hart.evaluate_true(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b8771-7632-450e-9f78-662bc5d591cc",
   "metadata": {
    "id": "874b8771-7632-450e-9f78-662bc5d591cc"
   },
   "source": [
    "## Run the Bayesian optimization\n",
    "\n",
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9239a9-3aeb-4191-9d87-96f7cf741fff",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650982592066,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "2a9239a9-3aeb-4191-9d87-96f7cf741fff"
   },
   "outputs": [],
   "source": [
    "n_exp = 1                   # number of experiments\n",
    "n_iter = 200                # number of iterations\n",
    "print_period = 10           # results are printed every print_period iteration\n",
    "n_train_ini = 20            # number of initial training examples\n",
    "output_folder = \"/content\" if running_on_colab else \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d08be-9c7a-44bd-91f5-415133b26afe",
   "metadata": {
    "id": "964d08be-9c7a-44bd-91f5-415133b26afe"
   },
   "source": [
    "### Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a07469-1ee4-4134-8212-dba15e6bc874",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63001,
     "status": "ok",
     "timestamp": 1650982657463,
     "user": {
      "displayName": "Arthur Bauville",
      "userId": "13412020910432312638"
     },
     "user_tz": -540
    },
    "id": "45a07469-1ee4-4134-8212-dba15e6bc874",
    "outputId": "1a05d2ba-de6d-4f19-ba2f-b0691c66f1a1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment  0\n",
      "=============\n",
      "010/200, best_f: 2.82129, last_f: 2.82129\n",
      "020/200, best_f: 3.23044, last_f: 3.22206\n",
      "030/200, best_f: 3.24713, last_f: 1.04245\n",
      "040/200, best_f: 3.24713, last_f: 1.85582\n",
      "050/200, best_f: 3.24713, last_f: 0.71376\n",
      "060/200, best_f: 3.24713, last_f: 0.12121\n",
      "070/200, best_f: 3.24713, last_f: 0.45214\n",
      "080/200, best_f: 3.24713, last_f: 1.69897\n",
      "090/200, best_f: 3.24713, last_f: 2.81527\n",
      "100/200, best_f: 3.31007, last_f: 1.14933\n",
      "110/200, best_f: 3.31314, last_f: 0.42807\n",
      "120/200, best_f: 3.31314, last_f: 0.00406\n",
      "130/200, best_f: 3.31314, last_f: 3.10615\n",
      "140/200, best_f: 3.31314, last_f: 0.00078\n",
      "150/200, best_f: 3.31314, last_f: 0.05847\n",
      "160/200, best_f: 3.31314, last_f: 0.61686\n",
      "170/200, best_f: 3.31314, last_f: 0.03790\n",
      "180/200, best_f: 3.31314, last_f: 0.21018\n",
      "190/200, best_f: 3.31314, last_f: 0.12364\n",
      "200/200, best_f: 3.31314, last_f: 2.56646\n"
     ]
    }
   ],
   "source": [
    "for i_exp in range(n_exp):\n",
    "    clear_output()\n",
    "    print(f\"Experiment {i_exp: 02d}\")\n",
    "    print( \"=============\")\n",
    "    best_fs = run_experiment(gt_func, n_iter, n_train_ini, print_period=print_period)\n",
    "\n",
    "    # Save intermediate results\n",
    "    # ============================\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    np.save(f\"{output_folder}/{timestamp}_best_fs\", best_fs)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "00_benchmark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
